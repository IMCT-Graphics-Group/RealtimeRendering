## 读书笔记: Real-time Rendering 4th Edition

### 0. 笔记前言

很难想象，我本来应该是看Pbrt并且深耕光线追踪的，但我却突发奇想决定先过一遍rtr，但仔细梳理逻辑又并不是没有根据的：Pbrt-v4出版在即，新版本引入了对Optix的支持，令我神往，所以先暂缓对Pbrt的学习；rtr更像一本算法目录，提供了大量有关光栅化、实时光追的内容，而我的研究内容是关于实时Pt的，也许可以通过rtr打开思路；最后一点大概就是对于工程的懈怠吧，我暂时觉得自己还没有做好为学习Pbrt做大量工程实践的准备，在这个还不算忙碌的研一下学期，抓住最后一点自由的时间，好好地享受阅读rtr的快乐吧~

### 1. 图形渲染管线

管线（或称为流水线），是一种有效提高生产效率的方式。通过将生产全流程拆解成$n$个不同的管线阶段，可以将生产速度提升$n$倍。但管线的生产效率受制于其最慢的管线阶段（木桶效应）。宏观上，渲染管线可以分成四个阶段：应用阶段→几何处理阶段→光栅化阶段→像素处理阶段。实际使用中，每一个阶段的内部又可以继续细分成更多的阶段。

- **应用阶段**：应用阶段由具体的应用驱动，通常表现为由CPU端执行的渲染前准备和渲染调度任务。由于应用阶段在CPU端执行，所以开发者具有完全的控制权，应用阶段的处理也会很大程度上影响后续阶段的执行，比如优化算法来减少需要绘制的三角形数量。应用阶段的一些工作也可以通过`Compute Shader`交给GPU处理。应用阶段最终会将需要绘制的几何信息传递给下一个阶段，这些几何信息通常描述了一些基础的图形元素，比如点、线、三角形。另外，碰撞检测、交互设备（鼠标、键盘、手柄、头显等）的信息处理也都在该阶段进行。

- **几何处理阶段**：几何处理阶段主要负责坐标变换、投射等与几何处理相关的任务。这个阶段会计算出哪些内容需要被绘制、应当怎样绘制，以及绘制到哪里。几何处理阶段一般在GPU上执行。几何处理阶段执行逐三角形和逐顶点的处理操作，这个阶段具体分为四个阶段：

  1. **顶点着色**：顶点着色阶段有两个主要任务：计算出顶点的位置、顶点输出数据（法线、纹理坐标等）。经典的物体着色都是在顶点上计算光照并存储颜色，然后在三角形中插值。这类可编程的顶点着色单元被称为顶点着色器。随着GPU硬件的发展，物体着色基本从顶点着色转换为像素着色，而原先的顶点着色器则被用作一个通用的处理阶段，用于计算各顶点的数据。顶点数据处理包含多次坐标系变换：顶点最初位于所属模型的`模型空间`，每个模型可以生成多个实例副本，每个实例都含有一个`模型变换（矩阵）`，描述了模型的缩放、位置和朝向，`模型变换（矩阵）`作用于模型的顶点和法线，变换之前的坐标系为`模型坐标系`，变换之后的坐标系为`世界坐标系`；为了便于相机投影和裁剪，所有处于`世界坐标系`下的物体都会进行`视图变换（矩阵）`，变换后的物体将处于`相机空间`，相机将位于坐标系原点，朝向$z$轴的负方向，$y$轴朝上，$x$轴朝右。除了`坐标变换`输出新的坐标之外，顶点着色还可以对顶点进行`着色`。有的渲染管线中，`着色`计算发生在几何处理阶段（逐顶点着色），有的则发生在像素处理阶段（逐像素着色）。顶点着色输出的着色数据（颜色、向量、纹理坐标等）将传递到光栅化阶段和像素处理阶段，用于插值和计算最终的表面颜色。顶点着色中，渲染管线底层还会先后执行`投影`和`裁剪`，将`视锥体`变换为从(-1,-1,-1)到(1,1,1)的立方体（或者0~1）。先执行`投影`变换，有`正交投影`和`透视投影`两种投影方式，`正交投影`是一种平行投影，常用于建筑领域，`透视投影`则是模拟人眼观察事物的方式。`视锥体`是将相机张开的角锥体保留近裁切面和远裁切面之内的部分得到的。经过`投影`变换之后，模型将处于`裁剪空间`，`裁剪坐标`是一种齐次坐标。根据齐次坐标缩放（除以$w$）后得到标准设备坐标系下的坐标（$ndc$），最后再将$ndc$坐标转换到窗口坐标。

  2. **细分着色（可选）**：为了使靠近的物体呈现更多的几何细节，可以通过细分着色器来生成更多的三角形面片。

  3. **几何着色（可选）**：几何着色器的出现早于细分着色器，所以有更多的GPU支持。和细分着色器类似，几何着色器也可以生成新的几何顶点。几何着色器可以生成的范围很有限，用得不多。最常见的情况是用于粒子系统：几何着色器将单个点转换为一个朝向相机的四边面，这样就可以方便地着色。

  4. **流输出（可选）**：使用流输出可以将处理好的顶点数据输出到一个数组里，用于其他处理，而不是送入渲染管线的后续阶段。流输出常用于粒子模拟。

     **关于裁剪**：只有裁剪空间之内的元素需要被送进下一个光栅化阶段。对于完全处于视锥体外的元素，将被直接丢弃；完全处于视锥体内的元素，将被直接送入下一个阶段；只有部分处于视锥体内的元素需要进行裁剪。举例，当一条直线部分地处于视锥体内时，将裁剪掉处于视锥体外的顶点，并用一个新的顶点替代。裁剪空间中的顶点经过齐次除法（透视除法）后，转入$ndc$空间。

- **光栅化阶段**：光栅化阶段负责将顶点组装成三角形，并且找到被各个三角形覆盖的屏幕像素，将这些信息送入下一个处理阶段。光栅化阶段一般在GPU上执行。光栅化分成两个子阶段：三角形装配、三角形遍历。虽然以上两个子阶段都被称为“三角形_xx”，但实际上也对点和线处理。光栅化阶段也被称为“扫描转换”，意味着将屏幕空间的二维坐标顶点转换为屏幕像素。如何判定某个像素被三角形覆盖，取决于开发者对管线的设置。比如单点采样的方法就是检测某个像素的中心是否位于三角形中。也可以使用多点采样方法，比如超级采样或者多重采样。（三角形装配和遍历阶段是固定函数的GPU执行阶段）

  1. **三角形装配**：这个阶段负责计算三角形各边的表达式以及其他各种数据。这些数据会在三角形遍历阶段中参与插值。
  2. **三角形遍历**：这个阶段会检查像素中心（或采样点）是否被三角形覆盖，然后生成三角形所覆盖的片元。每个三角形片元的属性都是由三角形的顶点插值得到的；透视矫正也发生在这个阶段。

- **像素处理阶段**：像素处理阶段会逐像素地执行一段程序，这段程序将计算出该像素的颜色。这个计算过程也许很复杂：可能会先执行深度测试，确定是否需要被绘制；也可能会执行颜色混合，将当前计算出的颜色和已有颜色混合。像素处理阶段一般在GPU上执行。像素处理阶段分为像素着色阶段和合成阶段。

  1. **像素着色**：可编程的着色器阶段，最终将一个或多个颜色送入下一阶段。
  2. **合成**：将像素着色阶段输出的颜色合成。也被称为**ROP**（raster operations pipeline）（render output unit）。该阶段虽然不可编程，但是高度可配置。这个阶段也会负责解决可见性问题（Z-Test&Z-Write）。早期的图形API中，也会在合成阶段处理Alpha-Test来丢弃完全透明的片元；现代的图形API则可以在可编程的阶段控制丢弃片元。模板缓冲（stencil buffer）是一个后台缓冲，用于记录各个元素的位置信息（一般是8bit每像素）。**模板缓**冲会被用于控制颜色缓冲和深度缓冲。举个例子：一个实心圆被写入了模板缓冲，后续的元素写入就可以依据该模板缓冲，仅写入实心圆所覆盖的区域。**帧缓冲（framebuffer）**是由全部缓冲组成的。

### 2. 图形处理单元

GPU采用了和CPU很不一样的处理方式。GPU芯片的绝大多数面积都用于放置数千个**shader cores**。GPU是一种**流处理器**，大量排好序的相似数据将依次执行。正是由于数据的相似性（比如顶点数据集或者像素数据集），GPU才可以最大程度地并行执行。另一个重要的因素是，GPU会尽可能地将调度彼此独立，这样就不需要相邻指令的调度信息，也不需要共享内存的写入地址。GPU对吞吐量（数据的最大处理速率）进行了专门优化，代价是GPU上减少了缓存和控制单元的面积，这也使得GPU上的延迟比CPU更高。使用同一段着色器程序的GPU线程会被捆成一组，NVIDIA称之为**warp**，AMD称之为**wavefront**。每个warp/wavefront会用多个 shader cores执行，通常是8~64个cores，通过SIMD处理技术。举例，有2000个线程需要执行，每个NVIDIA Warp如果由32个线程组成，则需要$2000\div32=62.5$个warps，也就是实际使用63个warps执行（其中有一个warp半空）这些任务。由于是SIMD，所以当一个warp中有线程遇到需要读取内存的情形时，所有的32个线程都是同时遇到的，warp中的线程会进行换出操作，先执行下一个warp的32个线程，等待内存读取完毕后再继续执行之前的线程。每个线程都有一个寄存器，用于临时存储执行状态，合适的时候可以恢复之前的执行任务。当然，warp执行换入换出操作的时机是不一定的，这和优化策略有关，由于换入换出的延迟很低，所以有许多优化技术都会用在warp的换入换出上。shader代码结构也会在很大程度上影响执行效率，如果一段shader程序**过度地使用寄存器**，那么分配给每个线程的寄存器就会变多，线程和warp的数量就会被迫减少，warp换出优化就没法使用。GPU中的warp占用率越高，意味着GPU的使用越充分，性能表现越好。另一个影响执行效率的重要因素是**动态分支**，主要由if语句和循环语句引发。当shader程序遇到if分支时，如果它们结果相同，走相同的分支，没有任何问题；但只要有一条线程走其他分支，那么整个warp都必须把涉及到的分支全部执行一遍，然后丢弃掉错误分支的结果。这类问题被称为**线程发散（thread divergence）**，即只有一小部分线程需要执行其他分支，却导致整个warp一起执行（或等待）的情况。

GPU实现了渲染管线（逻辑模型）中的几何处理、光栅化和像素处理阶段。其中最重要的是四个可编程的阶段：顶点着色、细分着色（可选）、几何着色（可选）和像素着色。现代GPU为着色器编程提供了统一的设计，这意味着四个可编程阶段使用相同的编程模型。从本质上来说，它们具有相同的指令集架构（ISA）。DirectX中称实现了该编程模型的处理核心为“通用着色器处理核心（common-shader core）”，具备这种核心的GPU被称为具备“统一着色器架构”。这种设计背后的思路是，着色处理器可以用于许多不同的情形，GPU可以统一一致地处理。比如，如果一组模型网格中含有大量的小三角形，而另一组大的四边形面片都是由两个三角形组成的，那么前者需要更多的顶点着色处理，后者则主要依赖于像素着色处理；如果区分使用顶点着色处理核心和像素着色处理核心，那么在需求不平衡的情况下，资源就会闲置；而使用统一的着色处理核心就可以由GPU平衡处理任务。

DirectX的HLSL可以被编译为中间语言（IL, or DXIL），实现硬件解耦，然后再由GPU的驱动器使用相应的ISA编译。

基础的数据类型为32-bit单精度浮点标量和向量，但向量只是着色器代码的一部分。现代GPU一般也会提供32-bit整型和64-bit浮点类型的支持。浮点向量比较常见的是位置信息(xyzw)、法线信息、矩阵行、颜色信息(rgba)、纹理坐标(uvwq)；整型常被用于计数器、索引、掩码。合成数据类型，比如结构体、数组和矩阵，也都是支持的。

一次draw call指令会调用图形API进行一组图形元素的绘制，相继地会由图形管线执行其中的shader。每个可编程的着色阶段都有两种类型的输入数据：统一输入数据，一次draw call中不会变化的数据；可变输入数据，由三角形顶点或光栅化产生。举例，像素着色会提供统一的光源数据，而三角形面的位置数据则是可变数据。纹理是一种特殊的统一数据，曾经是一张彩色图片，现在一般会被当做数组数据。

底层的虚拟机会对不同类型的数据提供不同类型的寄存器。统一数据可以获取的常量寄存器数量是远远大于可变数据的，这是由于不同顶点和像素的可变数据需要分开来单独存储，所以在寄存器数量上有着天然的限制。

 Shader的流程控制有两种：静态流程控制是以统一输入数据控制的，这意味着在一次draw call中的分支结果不会发生改变；动态流程控制则是以可变输入数据控制的，这意味着每个片元执行的代码可能都是不一样的。

#### 2.1 细分着色器（Tessellation Stage）

细分着色器分为三个部分：外壳着色器（hull shader / tessellation control shader）、细分器（tessellator）和域着色器（domain shader / tessellation evaluation shader）。

输入外壳着色器的是一些图元，这些图元由控制点组成，这些控制点以某种曲线形式（如贝塞尔）定义了细分面。外壳着色器有两个功能，第一个功能是告诉接下来的细分器有多少三角形需要生成，以及它们的相关配置；第二个功能是它可以对每个控制点进行处理，可以修改这些控制点的信息，或者增删控制点。外壳着色器将处理好的控制点和细分控制数据输出到域着色器。

细分器是一个固定函数阶段，仅用于细分着色器中，负责生成新的顶点传递给域着色器。外壳着色器会将细分器需要的信息传递过去，比如细分面的类型（三角面、四边面或者线束）、细分系数（tessellation factor）。细分系数包括两种类型：内边系数、外边系数。内边系数决定了图元内部的细分程度；外边系数决定了图元边缘挤出的分段数。

域着色器有着和顶点着色器类似的数据流模式，将每一个由细分器输入的顶点处理后生成一个相应的输出顶点。域着色器使用重心坐标计算出每个顶点的位置、法线、纹理坐标等各种信息。

#### 2.2 几何着色器（Geometry Shader）

几何着色器可以将图元转换为其他类型的图元，这是细分着色器无法实现的。比如将三角形网格的每天边转换为线段，则网格就可以转变为线框。

几何着色器的输入是一个物体和它的顶点。几何着色器也可以定义和处理扩展图元，实际上，一个三角形可以扩展三个额外顶点，一个线段也可以扩展额外的两个顶点。

几何着色器用于修改输入数据，或者做一些简单的拷贝，它不能生成任何图元。常被用于生成级联阴影、不同尺寸的粒子、为毛发渲染挤出边缘等。

几何着色器保证了输出的图元顺序与输入图元的顺序相同，这也导致几何着色器不适合在一次调用中复制或创建大量的几何体。

一次draw call中GPU可能产生绘制对象的阶段只有三个：光栅化、细分着色器和几何着色器。其中，几何着色器是最难预测的，很多移动端设备的几何着色器都是软件实现的，所以很少乃至不鼓励使用几何着色器。

#### 2.3 流输出（Stream Output）

流输出可以在光栅化之前将数据输出并存储起来，跳过后续的阶段。常被用于模拟水面流动或者粒子效果等。流输出的数据都是浮点类型，所以对显存有着明显的开销。另外，流输出按照图元存储数据，所以三角形就会在每个顶点存储多个数据，开销比较高；一种常见的处理方法是，将图元都转为点数据进行流输出。送入流输出的图元顺序是不会被改变的。

#### 2.4 像素着色器（Pixel Shader）

受益于MRT（multiple render targets）技术，一个rendering pass可以生成多张图像，比如同时生成颜色图片、ID图片和世界空间距离图片。MRT技术也带来了不同类型的渲染管线，比如延迟渲染，第一个pass存储物体的位置和材质信息，后续的pass对其进行着色。一般来说，像素着色器无法获取到相邻像素的信息，但是有一个间接方法，可以通过获取当前像素和相邻像素的梯度信息（差值）来重建相邻像素的值，但这就要求所有同组的像素着色都使用相同的指令。

DX11提供了一种可以向任意位置写入信息的缓冲类型，称为unordered access view(UAV)。最初仅允许像素着色器和计算着色器使用UAV，在DX11.1中更新为所有的可编程着色器都可以使用。该技术在OpenGL4.3中出现，称为shader storage buffer object(SSBO)。GPU使用专用的原子单元避免数据竞争的情况，但也因此会产生略微的阻塞。DX11.3提供了Rasterizer order views(ROVs)来保证执行顺序，这样就可以在像素着色器阶段编写颜色混合的算法而不再需要合成阶段，代价是会产生一些阻塞而牺牲性能。

#### 2.5 合成阶段（Merging Stage）

大部分传统管线中，模板缓冲和深度缓冲的操作都发生在该阶段。当片元可见时，颜色混合也会发生在这个阶段（对于不透明物体来说，没有颜色混合，而是颜色替换）。

但由于深度缓冲在传统流水线中的位置比较靠后，导致了大量无效的计算，所以许多GPU会在像素着色器之前进行合成阶段的测试。片元的一些信息（深度）被用于测试可见性，不可见的片元会被提前裁剪掉，这项功能被称为early-z。像素着色器中是可以对片元的深度信息进行调整的，也可以控制片元是否被丢弃，所以一旦有这些操作，为了防止冲突，early-z就不会执行，但也会使得管线效率略微下降。

#### 2.6 计算着色器（Compute Shader）

有一些平台是为了实现通用GPU计算的，比如CUDA和OpenCL，这类框架一般是使用C/C++这样的语言并扩展实现一些使用GPU的库。

DX11推出了compute shader用于通用的GPU计算，这个shader并不参与渲染管线的运作。但compute shader和渲染结合紧密，因为它由图形API调用，它使用和统一着色器相同的计算资源池。由于计算着色器的线程之间可以共享显存，有些操作在计算着色器中可能会更快。

### 3. 变换

从旋转矩阵中提取欧拉角：由于旋转矩阵$\textbf E(h,p,r)=\textbf R_z(r)\textbf R_x(p)\textbf R_y(h)$，将矩阵展开可以得到$e_{21}=sinp,\quad\frac{e_{01}}{e_{11}}=\frac{-sinr}{cosr}=-tanr,\quad\frac{e_{20}}{e_{22}}=\frac{-sinh}{cosh}=-tanh$。从而解出$p,r,h$。但如果$cosp=0$，那么$tanr和tanh$就不能正确求解，这时候可以假定$h=0，然后由\frac{e_{10}}{e_{00}}=\frac{sinr}{cosr}=tanr解出r值$。

变换矩阵行列式的值如果为负数，则该变换包含反射（负缩放）。

绕任意方向的旋转：先将任意方向**r**旋转到x轴方向，这需要构建旋转矩阵**M**，也就是找到和**r**相互垂直的向量。一种数值稳定的解法是，找到**r**最小的分量，将其设为0，交换剩下的两个分量的值，并将其中一个分量值取反。接着通过归一化和叉乘，就可以获得以**r**为轴的正交坐标系，从而建立旋转矩阵**M**。之后就可以将绕**r**旋转的问题转化为绕x轴旋转的问题，最后只需要应用$\textbf M^T$将其转回来即可。当然，Goldman还提出了一种旋转方法，他的变换矩阵可以参考书上P75。

四元数（P76）：$\hat{\textbf{q}}=(\textbf{q}_v,q_w)=iq_x+jq_y+kq_z+q_w=\textbf{q}_v+q_w=sin\phi\textbf{u}_q+cos\phi$

乘法：$\hat{\textbf{q}}\hat{\textbf{r}}=(\textbf{q}_v\times\textbf{r}_v+r_w\textbf{q}_v+q_w\textbf{r}_v,\quad q_wr_w-\textbf{q}_v\cdot\textbf{r}_v)$

加法：$\hat{\textbf{q}}+\hat{\textbf{r}}=(\textbf{q}_v+\textbf{r}_v,\quad q_w+r_w)$

共轭：$\hat{\textbf{q}}^*=(-\textbf{q}_v,q_w)$

模：$n(\hat{\textbf{q}})=\sqrt{\hat{\textbf{q}}\hat{\textbf{q}}^*}=\sqrt{\textbf{q}_v\cdot\textbf{q}_v+q_w^2}=\sqrt{q_x^2+q_y^2+q_z^2+q_w^2}$

单位量：$\hat{\textbf{i}}=(\textbf{0},1)$

求逆：$\hat{\textbf{q}}^{-1}=\frac{1}{n(\hat{\textbf{q}})^2}\hat{\textbf{q}}^*$

共轭法则：

- $(\hat{\textbf{q}}^*)^*=\hat{\textbf{q}}$
- $(\hat{\textbf{q}}+\hat{\textbf{r}})^*=\hat{\textbf{q}}^*+\hat{\textbf{r}}^*$
- $(\hat{\textbf{q}}\hat{\textbf{r}})^*=\hat{\textbf{r}}^*\hat{\textbf{q}}^*$

模法则：

- $n(\hat{\textbf{q}}^*)=n(\hat{\textbf{q}})$
- $n(\hat{\textbf{q}}\hat{\textbf{r}})=n(\hat{\textbf{q}})n(\hat{\textbf{r}})$

乘法规则：

- 分配律：$\hat{\textbf{p}}(s\hat{\textbf{q}}+t\hat{\textbf{r}})=s\hat{\textbf{p}}\hat{\textbf{q}}+t\hat{\textbf{p}}\hat{\textbf{r}}$
- 结合律：$\hat{\textbf{p}}(\hat{\textbf{q}}\hat{\textbf{r}})=(\hat{\textbf{p}}\hat{\textbf{q}})\hat{\textbf{r}}$
- 四元数乘法不服从交换律

对数运算：$log(\hat{\textbf{q}})=log(e^{\phi\textbf{u}_q})=\phi\textbf{u}_q$

指数运算：$\hat{\textbf{q}}^t=(sin\phi\textbf{u}_q+cos\phi)^t=e^{\phi t\textbf{u}_q}=sin(\phi t)\textbf{u}_q+cos(\phi t)$

将一个四维表示的点或者向量$\textbf{p}=(p_x,p_y,p_z,p_w)^T$视作四元数$\hat{\textbf{p}}$，则另一个单位四元数$\hat{\textbf{q}}=(sin\phi\textbf{u}_q,cos\phi)$可以对其进行四元数乘法$\hat{\textbf{q}}\hat{\textbf{p}}\hat{\textbf{q}}^{-1}$实现绕轴$\textbf{u}_q旋转2\phi$角度。

任何非零实数乘以$\hat{\textbf{q}}$得到的都是相同的变换，这意味着$\hat{\textbf{q}}和-\hat{\textbf{q}}$表示相同的变换，也意味着给旋转轴$\textbf{u}_q$以及实部$q_w$随意地增减负号，并不会影响四元数的旋转变换。

连续使用四元数旋转变换：$\hat{\textbf{r}}(\hat{\textbf{q}}\hat{\textbf{p}}\hat{\textbf{q}}^*)\hat{\textbf{r}}^*=(\hat{\textbf{r}}\hat{\textbf{q}})\hat{\textbf{p}}(\hat{\textbf{r}}\hat{\textbf{q}})^*=\hat{\textbf{c}}\hat{\textbf{p}}\hat{\textbf{c}}^*$

四元数转齐次矩阵：

$\textbf{M}^q=\begin{pmatrix}
&{1-s(q_y^2+q_z^2)} &{s(q_xq_y-q_wq_z)} &{s(q_xq_z+q_wq_y)} &{0}\\&{s(q_xq_y+q_wq_z)} &{1-s(q_x^2+q_z^2)} &{s(q_yq_z-q_wq_x)} &{0}\\&{s(q_xq_z-q_wq_y)} &{s(q_yq_z+q_wq_x)} &{1-s(q_x^2+q_y^2)} &{0}\\&{0} &{0} &{0} &{1}\end{pmatrix}$

其中$s=\frac{2}{(n(\hat{\textbf{q}})^2)}$

从矩阵中提取四元数则可以通过相互消元法得到，最后都和$q_{w}$相关，而$q_{w}$可以通过矩阵的迹得到：$tr(\textbf{M}^q)=4-2s(q_x^2+q_y^2+q_z^2)=4(1-\frac{q_x^2+q_y^2+q_z^2}{q_x^2+q_y^2+q_z^2+q_w^2})=\frac{4q_w^2}{(n(\hat{\textbf{q}}))^2}$

球面线性插值：$\hat{\textbf{s}}(\hat{\textbf{q}},\hat{\textbf{r}},t)=(\hat{\textbf{r}}\hat{\textbf{q}}^{-1})^t\hat{\textbf{q}}$

软件中的球面线性插值：$slerp(\hat{\textbf{q}},\hat{\textbf{r}},t)=\frac{sin(\phi(1-t))}{sin\phi}\hat{\textbf{q}}+\frac{sin(\phi t)}{sin\phi}\hat{\textbf{r}}$

其中，$cos\phi=q_xr_x+q_yr_y+q_zr_z+q_wr_w$

球面线性插值的本质是在一个单位球上构造了从$\hat{\textbf{q}}$（t=0）指向$\hat{\textbf{r}}$（t=1）的最短弧。

已知两个单位方向$\textbf{s}和\textbf{t}$，则实现$\textbf{s}转到\textbf{t}$的旋转四元数$\hat{\textbf{q}}$可以表示为：$\hat{\textbf{q}}=(\textbf{q}_v,q_w)=(\frac{1}{\sqrt{2(1+e)}}(\textbf{s}\cross\textbf{t}),\frac{\sqrt{2(1+e)}}{2})$

其中，$e=\textbf{s}\cdot\textbf{t}=cos(2\phi),\quad \norm{\textbf{s}\cross\textbf{t}}=sin(2\phi)$

上述表示法避免了两方向相近时的数值不稳定性，但当两方向相反时，仍然会出现分母为零的情况，遇到这种情况时，任何垂直于两方向的向量都可以作为转轴。

#### 3.2 顶点混合

顶点混合用于解决不同物体的衔接处在发生变换时的过渡问题。衔接处的模型可能会受到来自不同物体变换矩阵的影响。

第一种顶点混合的方法：找到所有会对目标顶点产生影响的骨骼，将它们的变换矩阵按照权重进行混合，得到对顶点的变换矩阵。

第二种顶点混合的方法：找到所有会对目标顶点产生影响的骨骼，对它们的变换矩阵作用于顶点的变换结果进行插值。

权重的和不一定为一，但这种情况一般是出现在使用一些特殊的算法，比如*morph targets*

顶点混合的一个缺点是，混合处可能会产生折叠和穿插。一种解决方案是使用“对偶四元混合（双四元混合）”，平移部分也使用一个四元数表示，这样插值的时候是沿着圆弧插值的。但对偶四元混合也会引起膨胀问题，所以还有一种“旋转中心蒙皮法”可以选择。

#### 3.3 变形

模型的变形方法通常是在一个中性模型的基础上，根据权重叠加其与不同模型之间的差值得到的。

#### 3.4 几何缓存回放

对于高质量模型的变形动画，需要缓存每一帧的顶点位置，但这对硬盘读写的要求很高，通常会采用一些优化方案。首先是对数据进行压缩，通过16-bit的整型来存储位置和纹理坐标，会产生压缩损失；其次可以通过对时间、空间重新编码来压缩数据，仅存储它们的差值。

#### 3.5 投影

- 正交投影：最简单的正交投影可以直接把z分量设为零，但一般来说，在正交投影中希望约束投影的范围。更常见的正交投影通常由六个分量描述（$l,r,b,t,n,f$）分别代表左、右、底、顶、近、远，六个平面。
- 投影矩阵将约束空间压缩成一个轴对齐的方盒，在OpenGL中，这个方盒的坐标是从(-1,-1,-1)到(1,1,1)；在DirectX中则是从(-1,-1,0)到(1,1,1)。这个方盒被称为*canonical view volume*（标准视体），其中的物体坐标被称为*normalized device coordinates*（归一化设备坐标）。使用标准视体可以使裁剪变得更容易和高效。
- 透视投影相对复杂很多，需要考虑深度的存储和矫正。

### 4. 着色

*Punctual Lights*为“点”光源（词源为拉丁语“punctus”），是指光源本身没有大小和形状，但是有一个特定的位置。“点光源”和“聚光灯源”都属于“点”光源。(point and spotlight are two different forms of punctual lights)

光照衰减的平方反比虽然很简单也很正确，但在实际使用中却有很多问题，比如当距离无限接近零时，会出现“除以零”的情况；所以一般在使用的时候，会加一个小的固定偏差值$\epsilon$，虚幻引擎使用$\epsilon=1 cm$；CryEngine和Frostbite Game Engine中使用的方法是使用$r=max(r,r_{min})$。相比于虚幻引擎的$\epsilon$可以任取，CryEngine采用的钳制方法有其物理意义，小于$r_{min}$的表面点意味着它穿插进了光源体的内部，这是不可能的。另一个问题是希望当光照衰减达到一定程度的时候，可以直接裁剪掉，减少性能开销；不同的引擎给出了不同的解决方案，基本都是修正出了一个光照衰减的曲线，达到某一距离时会衰减到零。

在设计着色实现方案时，需要根据**计算频率**划分计算。首先看这个计算结果在一次draw call中是否维持不变，如果不变的话可以由应用阶段计算；如果是硬件配置或者设置信息这种很少修改的结果，可以在编译阶段就存储起来，也就不必存到shader input中了，或者也可以通过一些离线的预计算pass，在应用程序的安装和加载阶段运行；另一种情况是修改的结果不需要立即应用起来，就可以把计算摊销到多个帧上；其他的划分还有逐帧的、逐模型的、逐draw call的等，根据**计算频率**分组可以有效提高执行效率、帮助GPU优化执行策略。

如果计算结果在一次draw call中也会发生改变，那么就需要依赖可编程着色器阶段来更新了，各个可编程阶段对应不同的计算频率：

- 顶点着色器：逐（细分前）顶点
- 壳着色器：逐面块
- 域着色器：逐（细分后）顶点
- 几何着色器：逐图元
- 像素着色器：逐像素

实际上，大部分的着色计算都是逐像素的，在像素着色器里执行；其他阶段主要执行一些几何相关的计算，比如变换和变形。

即使在顶点着色器中对向量归一化，在像素着色器中插值时，仍然会产生不符合归一化的插值结果，所以需要再次归一化。另外，如果输入向量没有进行归一化，插值结果很可能不正确。鉴于以上两点因素，在进行插值的前后通常都会对向量进行归一化处理。

通常会在顶点着色器中完成一些几何信息的坐标变换，减少像素着色器中的计算开销。坐标变换的方式需要整体考虑，从性能、灵活性和简便性的角度考虑。比如场景中存在大量光源时，使用世界空间坐标可以避免对光源坐标的变换；相机空间也是常用的坐标空间，在相机空间中运算可以优化有关视线方向的运算，也可以提升一些精度。

**Shader**输入有两种类型，第一种是统一输入，由应用层提供，并且在一次draw call中全程保持不变；第二种是可变输入，可以在不同着色器之间有所改变。

**材质**是一个艺术端概念，一种材质可能对应多个shader，一个shader也可能对应多种材质。参数化材质由两部分组成：材质模板和材质实例。有些渲染框架比如虚幻，可以设置更复杂的层级材质结构，即一种材质模板可以派生自其他模板而构成多个层级。

实现着色计算过程，对着色计算进行效率优化，通常有以下几种思路：

- 找到表达式中可以化简的部分
- 区分表达式中具有不同计算频率的部分，并调整其计算时期
- 在交互和跨平台支持中取得平衡，做合适的拆分与封装

**抗锯齿**问题的本质是一个采样问题。对于连续信号，计算机中通过对采样的离散信号重建来还原原本的信号。在离散采样的过程中会产生走样问题，走样是由采样频率低于实际频率引起的，计算机图形中的走样通常呈现为边缘锯齿或者高光闪烁。为了正确地重建连续信号，采样频率必须大于原始频率的二分之一，这被称为“采样定理”（奈奎斯特定理）。

但三维空间中的点采样几乎是无解的，无论采样点之间取多近，总可以存在更小的物体无法被采样到，所以对于使用点采样渲染图像的方法来说，是不可能彻底解决走样问题的。当然，有时也可以知道一些图像的频率带宽，比如对物体表面应用纹理贴图时，可以计算出屏幕像素的采样频率和纹理贴图的采样频率，如果符合奈奎斯特定理，则贴图采样过程不需要额外的处理。

信号重建需要使用滤波器，三种常用的滤波器分别是盒式滤波器（box filter）、帐篷型滤波器（tent filter）、正弦滤波器（sinc filter）；滤波器的面积需要为一，否则会造成重建信号被放大或者缩小。

box filter重建的信号并不连续，效果很差；tent filter重建的信号虽然连续，但不平滑，所以需要引入额外的低通滤波器；最理想的低通滤波器是sinc filter，该结论由傅里叶分析给出，简单来说，频域空间最好的滤波器是box filter（消除了频率大于滤波器宽度的所有信号），将box filter转换到空间域（图像域）时需要使用正弦函数；同时，滤波器在频域的叠加也会变成在空间域的卷积。

但是，sinc filter的宽度是无限的，而且有些区域是负的，所以实际中很少使用。实际中用得更多的是对sinc filter的近似滤波器，约束了单个滤波器的作用范围。越接近sinc filter的滤波器，越可能包含产生负数的部分，所以实际会使用一些不含负数的滤波器，比如高斯滤波器。

重建得到连续信号之后，并不能直接使用，因为计算机图形只能输出离散信号。但重建得到的连续信号可以调节信号大小，在此基础上可以重新采样信号进行输出。重采样中的上采样（减少采样间隔，更多的采样点）是容易进行的，只需要按照目标采样间隔采样重建的信号即可；降采样就会复杂一些，直接降低采样数会引起走样问题，所以需要使用sinc filter滤波器。

几种屏幕空间抗锯齿技术：

- **SSAA**：超级采样抗锯齿技术，使用更高的分辨率渲染图像，然后通过滤波获得目标分辨率的图片。该方法性能开销严重。
- 一种与SSAA类似的方法是，渲染出沿x,y方向偏移半个像素的同分辨率图像，通过**累积缓存**（遗弃，可使用高精度像素颜色混合）将这四张图像叠加起来。但由于需要重新绘制场景并且多次写入缓存，性能开销也非常严重。但相比于SSAA的优势是，对累积的图像数量没有限制，可以生成质量非常高的图片。
- 但物体边缘的走样问题仍然是一个严重问题，目前的主流方法是通过**分析法**解决。在渲染过程中找到物体的边缘，将边缘的影响因素考虑进抗锯齿中。
- **MSAA**：多重采样抗锯齿技术意识到对子像素进行完整运算所造成的计算开销过高，对其进行了优化（仅在光栅化阶段对子像素的覆盖进行额外计算）。如果所有子像素都被同一个物体片元所覆盖，那么该像素的颜色直接采用像素中心点的采样值；但如果覆盖的子像素比较少，则会使用合适的权重（占比）修正该像素中心位置的着色结果。该过程基本由GPU来实现（光栅化阶段由GPU负责），所以这是一个依赖于硬件的抗锯齿算法，虽然该算法效率很高，但是也可能会产生不正确的结果，对于延迟渲染的支持也很难说。总而言之，由于只进行一次着色计算，MSAA在提高计算效率的同时也节省了大量的显存空间。基于该技术，NVIDIA提供了CSAA，AMD提供了EQAA。
- NVIDIA的TXAA技术和MFAA技术都利用了**TAA**技术，使用之前渲染的多帧画面信息进行抗锯齿。但TAA技术会使静止的场景出现颜色溢出（发光）；使快速运动的物体出现鬼影。可以通过重投影的方法修正鬼影问题，即对画面生成速度缓冲用于寻找正确的采样点。由于TAA技术的效果很好，且不需要额外的采样点，成为了近几年最受欢迎的抗锯齿技术，而之前应用最多的MSAA则因为对延迟渲染的支持欠佳而逐渐遭到淘汰。
- 采样图案对抗锯齿的影响也是显著的。奈曼提出人眼对水平和竖直方向的边缘更加敏感，对接近45°的斜边也较为敏感。基于此，旋转网格超采样（RGSS）将采样图案旋转，使得水平和竖直方向可以被更多采样点覆盖。RGSS图案实际上是一类“拉丁超立方体采样”（分层采样）。但如果图案中的采样点沿着某个方向分布，则对与该方向平行的边缘采样的效果会很差，我们通常希望得到分布更加均匀的采样图案，因此分层采样方法常常和其他一些方法结合使用，比如抖动采样、霍尔顿序列、泊松圆盘等。
- **形态学方法**：锯齿通常出现在边缘，比如物体边缘、阴影边缘、高光边缘。形态学是指有关结构和形状的研究，形态学抗锯齿方法主要工作在于寻找和重建边缘。基于图像的方法会遇到一些问题，首先是边缘不一定能找到，当两个物体之间的颜色差别小于算法阈值时，就很难确定物体边缘；具有高对比度、高频率元素的物体表面，也容易误导算法，从而难以确定边缘；应用形态学抗锯齿常常会影响文本质量；图像抗锯齿算法也很难处理边角位置，一种处理方法是结合MSAA的子像素覆盖来确定边缘；图像抗锯齿算法处理不同的图像的时间复杂度也是不同的，草坪可能需要天空三倍的时间。总之，图像抗锯齿算法非常节省显存和算力，所以其应用面非常广；又由于其不依赖于其他信息，非常容易从渲染管线中解耦出来。最流行的图像抗锯齿算法是FXAA和SMAA，SMAA还可以结合MSAA的采样进行更好的抗锯齿处理，两种方法都可以和TAA结合。每帧的时间开销大约是1~2毫秒。

光线穿透半透明物体的方式有很多种，在渲染领域可以简单分为两类：基于光线的、基于相机的；基于光线的半透明效果侧重于光线穿透时的衰减和散射，会使周围的其他物体也被照亮；基于相机的半透明效果侧重于渲染半透明的物体本身。

一种透明渲染方法被称为“纱门透明”，使用一种带有透明部分的棋盘格图案渲染三角形面片，使得一部分被遮挡的物体露出来。这种方法的一个主要缺陷是，只有一层透明可以被渲染得很好；这种方法的主要优势是，足够简单，它可以在任何时间按任何顺序渲染透明物体，对硬件没有额外要求。

大部分的透明算法使用的是透明度混合技术。其中的$alpha$值指的是“不透明度”，即占比为$\alpha$的光线会被物体表面阻挡。

覆盖混合：$\textbf{c}_o=\alpha_s\textbf{c}_s+(1-\alpha_s)\textbf{c}_d$

覆盖混合在处理一些透明塑料和透明玻璃时的效果比较差，因为实际中的玻璃和滤镜等透明物体也会减少光线的穿透，从而使得最终的颜色更暗一些，而不是简单的颜色混合。

加法混合：$\textbf{c}_o=\alpha_s\textbf{c}_s+\textbf{c}_d$

加法混合对于发光效果很好用，比如闪电、火花，这些效果会使透明混合的部分更亮。加法混合对于大多数透明物体来说都不正确，但是用在多层透明的物体上（如烟雾、火焰）可以提亮颜色。

