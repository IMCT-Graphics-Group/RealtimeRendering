## 读书笔记: Real-time Rendering 4th Edition

### 0. 笔记前言

很难想象，我本来应该是看Pbrt并且深耕光线追踪的，但我却突发奇想决定先过一遍rtr，但仔细梳理逻辑又并不是没有根据的：Pbrt-v4出版在即，新版本引入了对Optix的支持，令我神往，所以先暂缓对Pbrt的学习；rtr更像一本算法目录，提供了大量有关光栅化、实时光追的内容，而我的研究内容是关于实时Pt的，也许可以通过rtr打开思路；最后一点大概就是对于工程的懈怠吧，我暂时觉得自己还没有做好为学习Pbrt做大量工程实践的准备，在这个还不算忙碌的研一下学期，抓住最后一点自由的时间，好好地享受阅读rtr的快乐吧~

### 1. 图形渲染管线

管线（或称为流水线），是一种有效提高生产效率的方式。通过将生产全流程拆解成$n$个不同的管线阶段，可以将生产速度提升$n$倍。但管线的生产效率受制于其最慢的管线阶段（木桶效应）。宏观上，渲染管线可以分成四个阶段：应用阶段→几何处理阶段→光栅化阶段→像素处理阶段。实际使用中，每一个阶段的内部又可以继续细分成更多的阶段。

- **应用阶段**：应用阶段由具体的应用驱动，通常表现为由CPU端执行的渲染前准备和渲染调度任务。由于应用阶段在CPU端执行，所以开发者具有完全的控制权，应用阶段的处理也会很大程度上影响后续阶段的执行，比如优化算法来减少需要绘制的三角形数量。应用阶段的一些工作也可以通过`Compute Shader`交给GPU处理。应用阶段最终会将需要绘制的几何信息传递给下一个阶段，这些几何信息通常描述了一些基础的图形元素，比如点、线、三角形。另外，碰撞检测、交互设备（鼠标、键盘、手柄、头显等）的信息处理也都在该阶段进行。

- **几何处理阶段**：几何处理阶段主要负责坐标变换、投射等与几何处理相关的任务。这个阶段会计算出哪些内容需要被绘制、应当怎样绘制，以及绘制到哪里。几何处理阶段一般在GPU上执行。几何处理阶段执行逐三角形和逐顶点的处理操作，这个阶段具体分为四个阶段：

  1. **顶点着色**：顶点着色阶段有两个主要任务：计算出顶点的位置、顶点输出数据（法线、纹理坐标等）。经典的物体着色都是在顶点上计算光照并存储颜色，然后在三角形中插值。这类可编程的顶点着色单元被称为顶点着色器。随着GPU硬件的发展，物体着色基本从顶点着色转换为像素着色，而原先的顶点着色器则被用作一个通用的处理阶段，用于计算各顶点的数据。顶点数据处理包含多次坐标系变换：顶点最初位于所属模型的`模型空间`，每个模型可以生成多个实例副本，每个实例都含有一个`模型变换（矩阵）`，描述了模型的缩放、位置和朝向，`模型变换（矩阵）`作用于模型的顶点和法线，变换之前的坐标系为`模型坐标系`，变换之后的坐标系为`世界坐标系`；为了便于相机投影和裁剪，所有处于`世界坐标系`下的物体都会进行`视图变换（矩阵）`，变换后的物体将处于`相机空间`，相机将位于坐标系原点，朝向$z$轴的负方向，$y$轴朝上，$x$轴朝右。除了`坐标变换`输出新的坐标之外，顶点着色还可以对顶点进行`着色`。有的渲染管线中，`着色`计算发生在几何处理阶段（逐顶点着色），有的则发生在像素处理阶段（逐像素着色）。顶点着色输出的着色数据（颜色、向量、纹理坐标等）将传递到光栅化阶段和像素处理阶段，用于插值和计算最终的表面颜色。顶点着色中，渲染管线底层还会先后执行`投影`和`裁剪`，将`视锥体`变换为从(-1,-1,-1)到(1,1,1)的立方体（或者0~1）。先执行`投影`变换，有`正交投影`和`透视投影`两种投影方式，`正交投影`是一种平行投影，常用于建筑领域，`透视投影`则是模拟人眼观察事物的方式。`视锥体`是将相机张开的角锥体保留近裁切面和远裁切面之内的部分得到的。经过`投影`变换之后，模型将处于`裁剪空间`，`裁剪坐标`是一种齐次坐标。根据齐次坐标缩放（除以$w$）后得到标准设备坐标系下的坐标（$ndc$），最后再将$ndc$坐标转换到窗口坐标。

  2. **细分着色（可选）**：为了使靠近的物体呈现更多的几何细节，可以通过细分着色器来生成更多的三角形面片。

  3. **几何着色（可选）**：几何着色器的出现早于细分着色器，所以有更多的GPU支持。和细分着色器类似，几何着色器也可以生成新的几何顶点。几何着色器可以生成的范围很有限，用得不多。最常见的情况是用于粒子系统：几何着色器将单个点转换为一个朝向相机的四边面，这样就可以方便地着色。

  4. **流输出（可选）**：使用流输出可以将处理好的顶点数据输出到一个数组里，用于其他处理，而不是送入渲染管线的后续阶段。流输出常用于粒子模拟。

     **关于裁剪**：只有裁剪空间之内的元素需要被送进下一个光栅化阶段。对于完全处于视锥体外的元素，将被直接丢弃；完全处于视锥体内的元素，将被直接送入下一个阶段；只有部分处于视锥体内的元素需要进行裁剪。举例，当一条直线部分地处于视锥体内时，将裁剪掉处于视锥体外的顶点，并用一个新的顶点替代。裁剪空间中的顶点经过齐次除法（透视除法）后，转入$ndc$空间。

- **光栅化阶段**：光栅化阶段负责将顶点组装成三角形，并且找到被各个三角形覆盖的屏幕像素，将这些信息送入下一个处理阶段。光栅化阶段一般在GPU上执行。光栅化分成两个子阶段：三角形装配、三角形遍历。虽然以上两个子阶段都被称为“三角形_xx”，但实际上也对点和线处理。光栅化阶段也被称为“扫描转换”，意味着将屏幕空间的二维坐标顶点转换为屏幕像素。如何判定某个像素被三角形覆盖，取决于开发者对管线的设置。比如单点采样的方法就是检测某个像素的中心是否位于三角形中。也可以使用多点采样方法，比如超级采样或者多重采样。（三角形装配和遍历阶段是固定函数的GPU执行阶段）

  1. **三角形装配**：这个阶段负责计算三角形各边的表达式以及其他各种数据。这些数据会在三角形遍历阶段中参与插值。
  2. **三角形遍历**：这个阶段会检查像素中心（或采样点）是否被三角形覆盖，然后生成三角形所覆盖的片元。每个三角形片元的属性都是由三角形的顶点插值得到的；透视矫正也发生在这个阶段。

- **像素处理阶段**：像素处理阶段会逐像素地执行一段程序，这段程序将计算出该像素的颜色。这个计算过程也许很复杂：可能会先执行深度测试，确定是否需要被绘制；也可能会执行颜色混合，将当前计算出的颜色和已有颜色混合。像素处理阶段一般在GPU上执行。像素处理阶段分为像素着色阶段和合成阶段。

  1. **像素着色**：可编程的着色器阶段，最终将一个或多个颜色送入下一阶段。
  2. **合成**：将像素着色阶段输出的颜色合成。也被称为**ROP**（raster operations pipeline）（render output unit）。该阶段虽然不可编程，但是高度可配置。这个阶段也会负责解决可见性问题（Z-Test&Z-Write）。早期的图形API中，也会在合成阶段处理Alpha-Test来丢弃完全透明的片元；现代的图形API则可以在可编程的阶段控制丢弃片元。模板缓冲（stencil buffer）是一个后台缓冲，用于记录各个元素的位置信息（一般是8bit每像素）。**模板缓**冲会被用于控制颜色缓冲和深度缓冲。举个例子：一个实心圆被写入了模板缓冲，后续的元素写入就可以依据该模板缓冲，仅写入实心圆所覆盖的区域。**帧缓冲（framebuffer）**是由全部缓冲组成的。

### 2. 图形处理单元

GPU采用了和CPU很不一样的处理方式。GPU芯片的绝大多数面积都用于放置数千个**shader cores**。GPU是一种**流处理器**，大量排好序的相似数据将依次执行。正是由于数据的相似性（比如顶点数据集或者像素数据集），GPU才可以最大程度地并行执行。另一个重要的因素是，GPU会尽可能地将调度彼此独立，这样就不需要相邻指令的调度信息，也不需要共享内存的写入地址。GPU对吞吐量（数据的最大处理速率）进行了专门优化，代价是GPU上减少了缓存和控制单元的面积，这也使得GPU上的延迟比CPU更高。使用同一段着色器程序的GPU线程会被捆成一组，NVIDIA称之为**warp**，AMD称之为**wavefront**。每个warp/wavefront会用多个 shader cores执行，通常是8~64个cores，通过SIMD处理技术。举例，有2000个线程需要执行，每个NVIDIA Warp如果由32个线程组成，则需要$2000\div32=62.5$个warps，也就是实际使用63个warps执行（其中有一个warp半空）这些任务。由于是SIMD，所以当一个warp中有线程遇到需要读取内存的情形时，所有的32个线程都是同时遇到的，warp中的线程会进行换出操作，先执行下一个warp的32个线程，等待内存读取完毕后再继续执行之前的线程。每个线程都有一个寄存器，用于临时存储执行状态，合适的时候可以恢复之前的执行任务。当然，warp执行换入换出操作的时机是不一定的，这和优化策略有关，由于换入换出的延迟很低，所以有许多优化技术都会用在warp的换入换出上。shader代码结构也会在很大程度上影响执行效率，如果一段shader程序**过度地使用寄存器**，那么分配给每个线程的寄存器就会变多，线程和warp的数量就会被迫减少，warp换出优化就没法使用。GPU中的warp占用率越高，意味着GPU的使用越充分，性能表现越好。另一个影响执行效率的重要因素是**动态分支**，主要由if语句和循环语句引发。当shader程序遇到if分支时，如果它们结果相同，走相同的分支，没有任何问题；但只要有一条线程走其他分支，那么整个warp都必须把涉及到的分支全部执行一遍，然后丢弃掉错误分支的结果。这类问题被称为**线程发散（thread divergence）**，即只有一小部分线程需要执行其他分支，却导致整个warp一起执行（或等待）的情况。

GPU实现了渲染管线（逻辑模型）中的几何处理、光栅化和像素处理阶段。其中最重要的是四个可编程的阶段：顶点着色、细分着色（可选）、几何着色（可选）和像素着色。现代GPU为着色器编程提供了统一的设计，这意味着四个可编程阶段使用相同的编程模型。从本质上来说，它们具有相同的指令集架构（ISA）。DirectX中称实现了该编程模型的处理核心为“通用着色器处理核心（common-shader core）”，具备这种核心的GPU被称为具备“统一着色器架构”。这种设计背后的思路是，着色处理器可以用于许多不同的情形，GPU可以统一一致地处理。比如，如果一组模型网格中含有大量的小三角形，而另一组大的四边形面片都是由两个三角形组成的，那么前者需要更多的顶点着色处理，后者则主要依赖于像素着色处理；如果区分使用顶点着色处理核心和像素着色处理核心，那么在需求不平衡的情况下，资源就会闲置；而使用统一的着色处理核心就可以由GPU平衡处理任务。

DirectX的HLSL可以被编译为中间语言（IL, or DXIL），实现硬件解耦，然后再由GPU的驱动器使用相应的ISA编译。

基础的数据类型为32-bit单精度浮点标量和向量，但向量只是着色器代码的一部分。现代GPU一般也会提供32-bit整型和64-bit浮点类型的支持。浮点向量比较常见的是位置信息(xyzw)、法线信息、矩阵行、颜色信息(rgba)、纹理坐标(uvwq)；整型常被用于计数器、索引、掩码。合成数据类型，比如结构体、数组和矩阵，也都是支持的。

一次draw call指令会调用图形API进行一组图形元素的绘制，相继地会由图形管线执行其中的shader。每个可编程的着色阶段都有两种类型的输入数据：统一输入数据，一次draw call中不会变化的数据；可变输入数据，由三角形顶点或光栅化产生。举例，像素着色会提供统一的光源数据，而三角形面的位置数据则是可变数据。纹理是一种特殊的统一数据，曾经是一张彩色图片，现在一般会被当做数组数据。

底层的虚拟机会对不同类型的数据提供不同类型的寄存器。统一数据可以获取的常量寄存器数量是远远大于可变数据的，这是由于不同顶点和像素的可变数据需要分开来单独存储，所以在寄存器数量上有着天然的限制。

 Shader的流程控制有两种：静态流程控制是以统一输入数据控制的，这意味着在一次draw call中的分支结果不会发生改变；动态流程控制则是以可变输入数据控制的，这意味着每个片元执行的代码可能都是不一样的。
